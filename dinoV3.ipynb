{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimavl2025/skin_cancer_clasification/blob/main/dinoV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d97bab3",
      "metadata": {
        "id": "4d97bab3"
      },
      "source": [
        "<big>First setp is to train the dinov2 classifier with labeled data</big>\n",
        "\n",
        "*Pre requirement:*\n",
        "\n",
        "*pip install torch torchvision timm scikit-learn*\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "unuFm6D3Vrke",
        "outputId": "73c4b7e5-770f-48ad-db7e-d9e7c20bcc2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "unuFm6D3Vrke",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEST SUBMISSION was with LR = 5e-4 and 50 epochs, weight_decay=1e-4 val_pos/neg = int(0.15\n",
        "\n",
        "# =========================\n",
        "# FULL COLAB SCRIPT (Option 1)\n",
        "# ResNet18 (NO pretrained weights) + Oversampling + Best F1 model\n",
        "# + Choose BEST threshold on VAL (maximize F1) + Kaggle submission (NO argmax)\n",
        "# =========================\n",
        "\n",
        "!pip -q install scikit-learn pandas tqdm\n",
        "\n",
        "import os, re, random, shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler, Subset\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# -------------------------\n",
        "# Mount Drive (safe)\n",
        "# -------------------------\n",
        "from google.colab import drive\n",
        "if not os.path.exists(\"/content/drive\"):\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "# -------------------------\n",
        "# Config\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 150\n",
        "\n",
        "NUM_WORKERS = 2\n",
        "IMG_SIZE = 224\n",
        "LR = 5e-4\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/Colab Notebooks/Course/Skin_Cancer_Classification\"\n",
        "\n",
        "# expected structure:\n",
        "# ROOT/train/0 , ROOT/train/1 , ROOT/test\n",
        "TRAIN_ROOT = os.path.join(ROOT, \"train\")\n",
        "TEST_DIR   = os.path.join(ROOT, \"test\")\n",
        "\n",
        "OUT_DIR = os.path.join(ROOT, \"models_resnet18_scratch\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "BEST_MODEL_PATH = os.path.join(OUT_DIR, \"best_resnet18_f1.pt\")\n",
        "SUB_VALTH_PATH  = os.path.join(OUT_DIR, \"submission_resnet18_bestValThreshold.csv\")\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility\n",
        "# -------------------------\n",
        "def seed_everything(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "id": "_H1kfAijBeCt",
        "outputId": "5fe8e346-09c4-4d59-bf39-3048f5fc7f9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_H1kfAijBeCt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 1: Ensure correct folder structure (move ROOT/0 and ROOT/1 into ROOT/train/0, ROOT/train/1 if needed)\n",
        "# -------------------------\n",
        "os.makedirs(TRAIN_ROOT, exist_ok=True)\n",
        "\n",
        "for cls in [\"0\", \"1\"]:\n",
        "    src_root = os.path.join(ROOT, cls)\n",
        "    dst_train = os.path.join(TRAIN_ROOT, cls)\n",
        "\n",
        "    if os.path.exists(dst_train):\n",
        "        print(f\"[OK] {dst_train} exists\")\n",
        "        continue\n",
        "\n",
        "    if os.path.exists(src_root):\n",
        "        print(f\"[MOVE] {src_root}  -->  {dst_train}\")\n",
        "        shutil.move(src_root, dst_train)\n",
        "    else:\n",
        "        print(f\"[WARN] Missing: {src_root} (and {dst_train} not found)\")\n",
        "\n",
        "assert os.path.isdir(os.path.join(TRAIN_ROOT, \"0\")), \"train/0 not found\"\n",
        "assert os.path.isdir(os.path.join(TRAIN_ROOT, \"1\")), \"train/1 not found\"\n",
        "assert os.path.isdir(TEST_DIR), \"test folder not found\"\n",
        "\n",
        "# -------------------------\n",
        "# Transforms\n",
        "# -------------------------\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.85, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(p=0.2),\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.10, hue=0.02),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "SNfBl3nnCDOD",
        "outputId": "efbd8524-2177-46a2-b078-5899d9913c52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SNfBl3nnCDOD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] /content/drive/MyDrive/Colab Notebooks/Course/Skin_Cancer_Classification/train/0 exists\n",
            "[OK] /content/drive/MyDrive/Colab Notebooks/Course/Skin_Cancer_Classification/train/1 exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 2: Dataset + stratified train/val split\n",
        "# -------------------------\n",
        "full_ds_train = datasets.ImageFolder(root=TRAIN_ROOT, transform=train_tfms)\n",
        "print(\"Classes:\", full_ds_train.classes, \"class_to_idx:\", full_ds_train.class_to_idx)\n",
        "\n",
        "targets = np.array([y for _, y in full_ds_train.samples])\n",
        "idx_all = np.arange(len(full_ds_train))\n",
        "\n",
        "pos_idx = idx_all[targets == 1]\n",
        "neg_idx = idx_all[targets == 0]\n",
        "\n",
        "rng = np.random.default_rng(SEED)\n",
        "rng.shuffle(pos_idx)\n",
        "rng.shuffle(neg_idx)\n",
        "\n",
        "val_pos = int(0.15 * len(pos_idx))\n",
        "val_neg = int(0.15 * len(neg_idx))\n",
        "\n",
        "val_idx = np.concatenate([pos_idx[:val_pos], neg_idx[:val_neg]])\n",
        "train_idx = np.concatenate([pos_idx[val_pos:], neg_idx[val_neg:]])\n",
        "rng.shuffle(train_idx)\n",
        "rng.shuffle(val_idx)\n",
        "\n",
        "train_ds = Subset(full_ds_train, train_idx)\n",
        "\n",
        "full_ds_val = datasets.ImageFolder(root=TRAIN_ROOT, transform=val_tfms)\n",
        "val_ds = Subset(full_ds_val, val_idx)\n",
        "\n",
        "train_targets = targets[train_idx]\n",
        "n0 = int((train_targets == 0).sum())\n",
        "n1 = int((train_targets == 1).sum())\n",
        "print(f\"Train count: 0={n0}, 1={n1} | ratio0/1={n0/max(n1,1):.2f}\")\n"
      ],
      "metadata": {
        "id": "njtcyrlHEHb7",
        "outputId": "b7b992f4-11b1-4232-cd31-c3f96c5d796f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "njtcyrlHEHb7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['0', '1'] class_to_idx: {'0': 0, '1': 1}\n",
            "Train count: 0=4250, 1=250 | ratio0/1=17.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 3: Oversampling via WeightedRandomSampler (balance sampling probability)\n",
        "# -------------------------\n",
        "LR = 5e-4\n",
        "class_counts = np.bincount(train_targets, minlength=2).astype(np.float64)\n",
        "class_weights = 1.0 / np.maximum(class_counts, 1.0)\n",
        "sample_weights = class_weights[train_targets]\n",
        "\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=torch.from_numpy(sample_weights).double(),\n",
        "    num_samples=len(train_targets),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                        num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "# -------------------------\n",
        "# Step 4: Model (ResNet18 from scratch)\n",
        "# -------------------------\n",
        "model = models.resnet18(weights=None)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_f1_argmax(model, loader):\n",
        "    model.eval()\n",
        "    ys, preds = [], []\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
        "            logits = model(x)\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        ys.append(y.detach().cpu().numpy())\n",
        "        preds.append(pred.detach().cpu().numpy())\n",
        "    ys = np.concatenate(ys)\n",
        "    preds = np.concatenate(preds)\n",
        "    return f1_score(ys, preds, pos_label=1)\n"
      ],
      "metadata": {
        "id": "kSMU5pw6EOAU",
        "outputId": "5213d3f7-8dc8-4d8a-bdf8-9e349ae909db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kSMU5pw6EOAU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2572813296.py:29: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c66f5cd",
      "metadata": {
        "id": "6c66f5cd",
        "outputId": "88e44c33-acfe-4f6d-ea01-8e8d28f11cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (ipython-input-2251890809.py, line 170)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2251890809.py\"\u001b[0;36m, line \u001b[0;32m170\u001b[0m\n\u001b[0;31m    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4f, weight_decay=1e-4)\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Step 5: Train (save best by val F1 using argmax internally for selection)\n",
        "# NOTE: This is only for model selection; final submission uses VAL-chosen threshold.\n",
        "# -------------------------\n",
        "best_f1 = -1.0\n",
        "best_epoch = -1\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", leave=False)\n",
        "    for x, y in pbar:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "        pbar.set_postfix(loss=float(loss.item()))\n",
        "\n",
        "    avg_loss = running_loss / len(train_ds)\n",
        "    val_f1 = eval_f1_argmax(model, val_loader)\n",
        "    print(f\"Epoch {epoch:02d} | train_loss={avg_loss:.4f} | val_f1(argmax)={val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        best_epoch = epoch\n",
        "        torch.save(\n",
        "            {\"model_state\": model.state_dict(), \"best_f1\": best_f1, \"epoch\": best_epoch},\n",
        "            BEST_MODEL_PATH\n",
        "        )\n",
        "        print(f\"  -> saved BEST model (val_f1={best_f1:.4f})\")\n",
        "\n",
        "print(\"Training done. Best val F1(argmax):\", best_f1, \"at epoch\", best_epoch)\n",
        "print(\"Best model saved to:\", BEST_MODEL_PATH)\n",
        "\n",
        "# -------------------------\n",
        "# Step 6: Load best model\n",
        "# -------------------------\n",
        "ckpt = torch.load(BEST_MODEL_PATH, map_location=device)\n",
        "model.load_state_dict(ckpt[\"model_state\"])\n",
        "model.eval()\n",
        "print(\"Loaded best model. epoch:\", ckpt.get(\"epoch\"), \"best_f1:\", ckpt.get(\"best_f1\"))\n",
        "\n",
        "# -------------------------\n",
        "# Step 7: Choose BEST threshold on VAL to maximize F1 (this is the key improvement)\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def collect_val_probs(model, loader):\n",
        "    model.eval()\n",
        "    probs, ys = [], []\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
        "            logits = model(x)\n",
        "            p1 = torch.softmax(logits, dim=1)[:, 1]\n",
        "        probs.append(p1.detach().cpu().numpy())\n",
        "        ys.append(y.detach().cpu().numpy())\n",
        "    return np.concatenate(probs), np.concatenate(ys)\n",
        "\n",
        "p_val, y_val = collect_val_probs(model, val_loader)\n",
        "\n",
        "ths = np.linspace(0.05, 0.99, 95)\n",
        "best = {\"th\": None, \"f1\": -1.0, \"prec\": None, \"rec\": None}\n",
        "\n",
        "for th in ths:\n",
        "    pred = (p_val > th).astype(int)\n",
        "    f1 = f1_score(y_val, pred, pos_label=1)\n",
        "    if f1 > best[\"f1\"]:\n",
        "        best[\"f1\"] = float(f1)\n",
        "        best[\"th\"] = float(th)\n",
        "        best[\"prec\"] = float(precision_score(y_val, pred, pos_label=1, zero_division=0))\n",
        "        best[\"rec\"]  = float(recall_score(y_val, pred, pos_label=1, zero_division=0))\n",
        "\n",
        "print(\"Best threshold on VAL (maximize F1):\")\n",
        "print(best)\n",
        "\n",
        "P_THRESH = best[\"th\"]\n",
        "print(\"Using threshold:\", P_THRESH)\n",
        "\n",
        "# -------------------------\n",
        "# Step 8: Test loader (NO labels; custom dataset)\n",
        "# Kaggle ID format: \"test/000000.jpg\"\n",
        "# Your filenames: \"jpg.000045\" -> \"test/000045.jpg\"\n",
        "# -------------------------\n",
        "test_files = [f for f in os.listdir(TEST_DIR) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
        "assert len(test_files) > 0, \"No images found in test folder\"\n",
        "\n",
        "def extract_number(fn: str) -> int:\n",
        "    m = re.findall(r\"\\d+\", fn)\n",
        "    return int(m[-1]) if m else -1\n",
        "\n",
        "test_files = sorted(test_files, key=extract_number)\n",
        "\n",
        "def filename_to_kaggle_id(fn: str) -> str:\n",
        "    num = extract_number(fn)\n",
        "    return f\"test/{num:06d}.jpg\"\n",
        "\n",
        "class TestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, folder, files, transform):\n",
        "        self.folder = folder\n",
        "        self.files = files\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        from PIL import Image\n",
        "        fn = self.files[idx]\n",
        "        path = os.path.join(self.folder, fn)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img = self.transform(img)\n",
        "        return img, fn\n",
        "\n",
        "test_tfms = val_tfms\n",
        "test_ds = TestDataset(TEST_DIR, test_files, test_tfms)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                         num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "# -------------------------\n",
        "# Step 9: Predict and create single submission using VAL-chosen threshold\n",
        "# -------------------------\n",
        "all_ids, all_p = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, fns in tqdm(test_loader, desc=\"Predict test\"):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
        "            logits = model(x)\n",
        "            p1 = torch.softmax(logits, dim=1)[:, 1]\n",
        "        p1 = p1.detach().cpu().numpy()\n",
        "\n",
        "        for fn, prob1 in zip(fns, p1):\n",
        "            all_ids.append(filename_to_kaggle_id(fn))\n",
        "            all_p.append(float(prob1))\n",
        "\n",
        "labels = (np.array(all_p) > P_THRESH).astype(int)\n",
        "\n",
        "sub = pd.DataFrame({\"ID\": all_ids, \"label\": labels})\n",
        "sub.to_csv(SUB_VALTH_PATH, index=False)\n",
        "\n",
        "print(\"Saved submission:\", SUB_VALTH_PATH)\n",
        "print(sub.head())\n",
        "print(\"Predicted positives:\", int(sub[\"label\"].sum()), \"/\", len(sub))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}