{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimavl2025/skin_cancer_clasification/blob/main/dinoV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d97bab3",
      "metadata": {
        "id": "4d97bab3"
      },
      "source": [
        "<big>First setp is to train the dinov2 classifier with labeled data</big>\n",
        "\n",
        "*Pre requirement:*\n",
        "\n",
        "*pip install torch torchvision timm scikit-learn*\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "unuFm6D3Vrke"
      },
      "id": "unuFm6D3Vrke",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c66f5cd",
      "metadata": {
        "id": "6c66f5cd"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 0. Install deps (run once per new runtime)\n",
        "# ============================================\n",
        "!pip install -q transformers scikit-learn\n",
        "\n",
        "# ============================================\n",
        "# 1. Imports & setup\n",
        "# ============================================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "from transformers import Dinov2Config, Dinov2ForImageClassification, AutoImageProcessor\n",
        "\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ============================================\n",
        "# 2. Paths & experiment definitions\n",
        "# ============================================\n",
        "MAIN_DIR = \"/content/drive/MyDrive/Colab Notebooks/Course/Skin_Cancer_Classification\"\n",
        "\n",
        "EXPERIMENTS = [\n",
        "    {\n",
        "        \"pos_folder\": \"1_generated_from_augmentation\",\n",
        "        \"exp_name\": \"dinov2_1_generated_from_augmentation\"\n",
        "    },\n",
        "    {\n",
        "        \"pos_folder\": \"1_generated from unlabeled\",  # note the space\n",
        "        \"exp_name\": \"dinov2_1_generated_from_unlabeled\"\n",
        "    }\n",
        "]\n",
        "\n",
        "SAVE_MODELS_DIR = os.path.join(MAIN_DIR, \"models\")\n",
        "os.makedirs(SAVE_MODELS_DIR, exist_ok=True)\n",
        "\n",
        "# ============================================\n",
        "# 3. Image processor for DINOv2\n",
        "#    (only config & preprocessing, NO weights)\n",
        "# ============================================\n",
        "# We re-use the official DINOv2 image processor to get\n",
        "# correct resize/normalization, but the model itself will\n",
        "# be created from a config (random weights).\n",
        "processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-small\")\n",
        "\n",
        "# ============================================\n",
        "# 4. Dataset definition\n",
        "# ============================================\n",
        "IMG_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "\n",
        "class SkinCancerDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, processor):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.processor = processor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
        "        # pixel_values shape: [1, 3, H, W] -> [3, H, W]\n",
        "        pixel_values = inputs[\"pixel_values\"].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            \"pixel_values\": pixel_values,\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "def collect_image_paths(folder):\n",
        "    paths = []\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for f in files:\n",
        "            if f.lower().endswith(IMG_EXTENSIONS):\n",
        "                paths.append(os.path.join(root, f))\n",
        "    return paths\n",
        "\n",
        "# ============================================\n",
        "# 5. Training & evaluation helpers\n",
        "# ============================================\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Train\", leave=False):\n",
        "        pixel_values = batch[\"pixel_values\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(pixel_values=pixel_values)\n",
        "        logits = outputs.logits  # [B, 2]\n",
        "\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * labels.size(0)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        total_correct += (preds == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    acc = total_correct / total_samples\n",
        "    return avg_loss, acc\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Val\", leave=False):\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(pixel_values=pixel_values)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            loss = criterion(logits, labels)\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            total_correct += (preds == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy().tolist())\n",
        "            all_preds.extend(preds.cpu().numpy().tolist())\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    acc = total_correct / total_samples\n",
        "\n",
        "    # Binary metrics for positive class = 1\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_preds, average=\"binary\", pos_label=1, zero_division=0\n",
        "    )\n",
        "\n",
        "    return avg_loss, acc, precision, recall, f1\n",
        "\n",
        "def plot_curves(train_losses, val_losses, train_accs, val_accs, exp_name):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"Loss - {exp_name}\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accs, label=\"Train Acc\")\n",
        "    plt.plot(epochs, val_accs, label=\"Val Acc\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(f\"Accuracy - {exp_name}\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ============================================\n",
        "# 6. Main training loop for each experiment\n",
        "# ============================================\n",
        "NUM_EPOCHS = 30\n",
        "BATCH_SIZE = 16   # adjust if you see OOM\n",
        "LR = 1e-4\n",
        "VAL_SPLIT = 0.2   # 80% train / 20% val\n",
        "\n",
        "for cfg in EXPERIMENTS:\n",
        "    pos_folder = cfg[\"pos_folder\"]\n",
        "    exp_name = cfg[\"exp_name\"]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"Starting experiment: {exp_name}\")\n",
        "    print(f\"Positive folder: {pos_folder}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 1) Collect image paths\n",
        "    neg_dir = os.path.join(MAIN_DIR, \"0\")\n",
        "    pos_dir = os.path.join(MAIN_DIR, pos_folder)\n",
        "\n",
        "    neg_images = collect_image_paths(neg_dir)\n",
        "    pos_images = collect_image_paths(pos_dir)\n",
        "\n",
        "    print(f\"Found {len(neg_images)} negative images (class 0)\")\n",
        "    print(f\"Found {len(pos_images)} positive images (class 1)\")\n",
        "\n",
        "    all_paths = neg_images + pos_images\n",
        "    all_labels = [0] * len(neg_images) + [1] * len(pos_images)\n",
        "\n",
        "    # 2) Train/val split (stratified)\n",
        "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "        all_paths,\n",
        "        all_labels,\n",
        "        test_size=VAL_SPLIT,\n",
        "        random_state=SEED,\n",
        "        stratify=all_labels,\n",
        "    )\n",
        "\n",
        "    print(f\"Train size: {len(train_paths)}, Val size: {len(val_paths)}\")\n",
        "\n",
        "    # 3) Build datasets & loaders\n",
        "    train_dataset = SkinCancerDataset(train_paths, train_labels, processor)\n",
        "    val_dataset = SkinCancerDataset(val_paths, val_labels, processor)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    # 4) Initialize DINOv2 model from CONFIG (NO pretrained weights)\n",
        "    config = Dinov2Config.from_pretrained(\n",
        "    \"facebook/dinov2-small\",\n",
        "    num_labels=2\n",
        ")\n",
        "    # we still initialize RANDOM weights (no pretrained checkpoint)\n",
        "    model = Dinov2ForImageClassification(config)\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "    # 5) Training loop\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
        "\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "        val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate(model, val_loader, criterion)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        print(\n",
        "            f\"Train  - loss: {train_loss:.4f}, acc: {train_acc:.4f}\\n\"\n",
        "            f\"Val    - loss: {val_loss:.4f}, acc: {val_acc:.4f}, \"\n",
        "            f\"P1: {val_prec:.4f}, R1: {val_rec:.4f}, F1: {val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "    # 6) Final evaluation on val set\n",
        "    val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate(model, val_loader, criterion)\n",
        "    print(\"\\n\" + \"-\"*80)\n",
        "    print(f\"Final validation metrics for {exp_name}:\")\n",
        "    print(f\"Loss: {val_loss:.4f}\")\n",
        "    print(f\"Accuracy: {val_acc:.4f}\")\n",
        "    print(f\"P1 (Precision for class 1): {val_prec:.4f}\")\n",
        "    print(f\"R1 (Recall for class 1):    {val_rec:.4f}\")\n",
        "    print(f\"F1 (F1 for class 1):        {val_f1:.4f}\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    # 7) Plot curves\n",
        "    plot_curves(train_losses, val_losses, train_accs, val_accs, exp_name)\n",
        "\n",
        "    # 8) Save model & processor for later predictions\n",
        "    save_dir = os.path.join(SAVE_MODELS_DIR, exp_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    model.save_pretrained(save_dir)\n",
        "    processor.save_pretrained(save_dir)\n",
        "\n",
        "    print(f\"Saved model + processor to: {save_dir}\")\n",
        "\n",
        "print(\"\\nAll experiments finished.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}